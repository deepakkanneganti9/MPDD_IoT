Machine Learning as a Service (MLaaS) is a powerful cloud paradigm enabling data-driven intelligent applications in Internet of Things (IoT) environments, widely adopted across healthcare, smart homes, and industry due to its cost-effectiveness. However, the dynamic nature of IoT frequently alters data distributions, affecting MLaaS stability, while periodic MLaaS updates further introduce performance drift. Unlike traditional ML systems, MLaaS clients operate as black-box users without access to internal data or parameters, making drift detection particularly challenging. To address this, we propose a novel MLaaS Performance Drift Detection framework for IoT environments. The framework first employs an MLaaS extraction model that learns service behavior from input–output pairs and identifies prediction-influenced features. Building on this, the proposed MLaaS Performance Drift Detection (MPDD) model jointly captures variations in input data and MLaaS behavior. We further design an Adaptive-Temporal Performance Drift Detection Mechanism (APDDM) that dynamically adjusts monitoring frequency based on behavioral and data variations, enabling timely drift detection for effective service management. Extensive experiments on real-world datasets demonstrate that MPDD achieves up to 20–25% accuracy improvement over baseline drift detection methods, while the adaptive APDDM provides an additional average accuracy gain of approximately 15% and reduces the miss detection rate by around 10% compared to fixed-interval monitoring.

Overview
This repository presents a comprehensive experimental evaluation of the MLaaS Performance Drift Detection (MPDD) framework in black-box MLaaS environments. The experiments are designed to analyze how performance drift emerges when data distributions evolve over time in dynamic IoT and real-world data streams.

The repository includes multi-dataset experimentation, adaptive temporal monitoring, and fidelity analysis of the MLaaS extraction model to ensure reliable drift detection without accessing internal MLaaS parameters.

The experiments collectively evaluate:

* Performance drift in black-box MLaaS systems
* Adaptive drift monitoring using APDDM
* Behavioural variation in MLaaS predictions under data drift
* Fidelity of the extraction model in mimicking MLaaS behaviour

Common Workflow

All notebooks follow a unified and reproducible experimental pipeline:

1. Dataset Loading and Preprocessing
   Each dataset (HAR, Electricity, Weather, Airline, and Poker) is loaded, cleaned, and normalized to ensure consistent experimental evaluation across domains.

2. Synthetic Drift Injection
   Controlled drift is injected to simulate realistic real-world changes such as:

* Sudden drift
* Gradual drift
* Incremental drift
* Seasonal and behavioural variations

3. MLaaS Extraction Model Training
   A lightweight surrogate extraction model is trained using MLaaS input–output query logs. This model approximates the observable behaviour of the black-box MLaaS service and enables behavioural monitoring over time.

4. MPDD-Based Performance Drift Evaluation

* Compare MLaaS predictions with ground truth labels
* Monitor accuracy degradation and behavioural shifts
* Compute detection delay, false negatives, false positives, and pseudo drift

5. Visualization and Analysis

* Drift detection timelines
* Accuracy degradation curves
* Adaptive interval behaviour (APDDM)
* Comparative performance metrics across datasets

Experiment 1: MPDD Framework Evaluation (Cross-Dataset Drift Analysis)

This experiment evaluates the robustness and generalization capability of the proposed MPDD framework across multiple real-world datasets with different drift characteristics and data modalities.

File: Experiment_1_MPDD_Framework_HAR_Dataset.ipynb
Dataset: Human Activity Recognition (PAMAP2 small)
Goal: Detect performance degradation in MLaaS predictions caused by sensor drift, user behaviour variation, and IoT data heterogeneity.
Key Focus: Human-centric IoT data with continuous behavioural drift.

File: Experiment_1_MPDD_Framework_Electricity_Dataset.ipynb
Dataset: Electricity Market Dataset
Goal: Detect real and pseudo drift events caused by dynamic electricity demand and pricing fluctuations.
Key Focus: Volatile temporal data streams and market-driven drift patterns.

File: Experiment_1_MPDD_Framework_Weather_Dataset.ipynb
Dataset: Weather History Dataset
Goal: Monitor MLaaS stability under gradual, seasonal, and environmental drift conditions.
Key Focus: Long-term environmental variability affecting prediction behaviour.

File: Experiment_1_MPDD_Framework_AIR_Dataset.ipynb
Dataset: Airline Delay Dataset (air_2019.csv)
Description: The Airline dataset contains large-scale flight records representing arrival and departure information, capturing temporal operational variations in real-world environments.
Goal: Evaluate MPDD under large-scale temporal drift caused by seasonal traffic, delays, and operational variability.
Key Focus: Real-world streaming data with strong temporal and distributional shifts.

File: Experiment_1_MPDD_Framework_Poke_Dataset.ipynb
Dataset: Poker Dataset (poke.csv)
Description: The Poker dataset comprises large-scale samples representing hands of five playing cards encoded using rank and suit features.
Goal: Assess MPDD performance in high-dimensional categorical data with complex feature combinations.
Key Focus: Structured yet highly variable data distributions and large sample scale.

Experiment 2: Adaptive Temporal Performance Drift Detection (APDDM)

File: Experiment_2_Adaptive_Temporal_PDM_Benchmark_dataset_Final.ipynb

This experiment extends the MPDD framework by incorporating the Adaptive-Temporal Performance Drift Detection Mechanism (APDDM) to dynamically adjust monitoring intervals.

Objective:
To automatically adapt the monitoring frequency based on behavioural variation and detected drift intensity in MLaaS predictions.

Mechanism:

* Shortens monitoring intervals when persistent real drift is detected
* Expands monitoring intervals when pseudo drift dominates
* Improves detection timeliness while reducing unnecessary false alarms

Datasets Used:
HAR, Electricity, Weather, Airline, and Poker datasets organized into benchmark evaluation folders.

Outputs:

* Adaptive vs fixed interval comparison plots
* Miss Detection (MD), False Negatives (FN), False Positives (FP)
* Detection delay and adaptive window evolution analysis

Experiment 3: Fidelity Analysis of MLaaS Extraction Model

File: Experiment_3_PMDD_Framework_HAR_Dataset_Final.ipynb

This experiment focuses on fidelity analysis of the MLaaS extraction model used within the MPDD framework.

Objective:
To evaluate how accurately the extraction (surrogate) model mimics the behaviour of the black-box MLaaS service over time.

Core Analysis:

* Fidelity score between MLaaS outputs and extraction model predictions
* Behavioural consistency under drift conditions
* Stability of learned decision patterns across temporal blocks

Methodology:

* Train extraction model using MLaaS input–output query logs
* Compare surrogate predictions with original MLaaS predictions
* Measure agreement, deviation, and behavioural drift sensitivity

Significance:
This experiment validates that the extraction model reliably represents MLaaS behaviour, ensuring that detected drift originates from actual service performance changes rather than surrogate modeling errors.

Outputs Across Experiments

* Drift detection plots over temporal blocks
* Accuracy degradation analysis
* Adaptive vs fixed monitoring comparisons
* Fidelity and behavioural agreement metrics
* Detection delay, false positives, and false negatives

Dependencies

Python: 3.9 or later
Libraries: numpy, pandas, matplotlib, scikit-learn, seaborn, tensorflow or torch

Repository Structure (Updated as per actual repository)

Datasets
├── Electricity.csv
├── air_2019.csv
├── pamap2_final_small.csv
├── poke.csv
├── weatherHistory 2.csv

Experiment 1
├── Experiment_1_MPDD_Framework_AIR_Dataset.ipynb
├── Experiment_1_MPDD_Framework_Electricity_Dataset.ipynb
├── Experiment_1_MPDD_Framework_HAR_Dataset.ipynb
├── Experiment_1_MPDD_Framework_Poke_Dataset.ipynb
├── Experiment_1_MPDD_Framework_Weather_Dataset.ipynb
└── README

Experiment 2
├── Airline
├── Electricity
├── HAR
├── Poker
├── Weather
├── Experiment_2_Adaptive_Temporal_PDM_Benchmark_dataset_Final.ipynb
├── adaptive_drift_results.csv
└── README

Experiment 3
├── Experiment_3_PMDD_Framework_HAR_Dataset_Final.ipynb
└── README

Root
└── README
